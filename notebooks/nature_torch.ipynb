{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17349986-f74b-45f8-baa4-3f5511725af6",
   "metadata": {},
   "source": [
    "# Nature CNN Recreation using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40dcc2a9-91a1-4d34-b14d-df73e2e21fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marcusp/Documents/traffic-sign-classification\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101baa1d-f2a0-4418-b6bf-0f7fed8bd17f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e2956fd-5eab-4067-b6d5-e412c6749a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataio.gtsrb_dataset import GTSRBDataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "# Define chosen classes\n",
    "chosen_classes = {1, 2, 10, 13, 38}\n",
    "labels = GTSRBDataset(labels=\"filtered_labels_encoded.csv\").labels_data  # Assuming labels_data is accessible\n",
    "\n",
    "# Filter indices for chosen classes\n",
    "filtered_indices = [i for i, (_, label) in enumerate(labels) if label in chosen_classes]\n",
    "\n",
    "# Group indices by class\n",
    "class_indices = {class_label: [] for class_label in chosen_classes}\n",
    "for index in filtered_indices:\n",
    "    _, label = labels[index]\n",
    "    if label in chosen_classes:\n",
    "        class_indices[label].append(index)\n",
    "\n",
    "# Clip each class to 2500 images and combine\n",
    "clipped_indices = []\n",
    "for label in chosen_classes:\n",
    "    indices = class_indices[label]\n",
    "    if len(indices) > 2500:\n",
    "        indices = np.random.choice(indices, size=2500, replace=False)\n",
    "    clipped_indices.extend(indices)\n",
    "\n",
    "# Shuffle the clipped indices\n",
    "clipped_indices = np.array(clipped_indices)\n",
    "np.random.shuffle(clipped_indices)\n",
    "\n",
    "# Split into training and testing sets\n",
    "dataset_length = len(clipped_indices)\n",
    "train_split = clipped_indices[:int(0.85 * dataset_length)]\n",
    "test_split = clipped_indices[int(0.15 * dataset_length):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95f748c9-affb-4aeb-afee-c09722e32428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(size=(28,28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(size=(28,28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "# Set up the datasets with for_torch=True\n",
    "train_dataset = GTSRBDataset(\n",
    "    labels=\"filtered_labels_encoded.csv\",\n",
    "    indices=train_split,\n",
    "    split=\"train\",\n",
    "    transforms=train_transforms,\n",
    "    for_torch=True  # Set the for_torch flag to True\n",
    ")\n",
    "\n",
    "test_dataset = GTSRBDataset(\n",
    "    labels=\"filtered_labels_encoded.csv\",\n",
    "    indices=test_split,\n",
    "    split=\"test\",\n",
    "    transforms=val_transforms,\n",
    "    for_torch=True  # Set the for_torch flag to True\n",
    ")\n",
    "\n",
    "# Set up the data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e93b3c3-d874-4f9d-8d84-59fdd45edbf2",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "409f3fd3-688b-472b-aa62-1538e7d0b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "# Define the model architecture\n",
    "layers = [\n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(in_features=256, out_features=120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=120, out_features=84),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=84, out_features=5)\n",
    "]\n",
    "\n",
    "# Create the model\n",
    "model = nn.Sequential(*layers)\n",
    "\n",
    "# Initialize weights with He initialization\n",
    "for layer in model:\n",
    "    if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
    "        init.kaiming_normal_(layer.weight, mode='fan_in', nonlinearity='relu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "895378f9-07b2-483d-a97f-c62ff28a297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "param_dict = dict(model.named_parameters())\n",
    "optimiser = optim.SGD(param_dict.values(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ec239-bd85-4385-85fe-b710f5ae9295",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a50aa80b-fdd9-4566-ba0a-e32b69870fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple\n",
    "\n",
    "def train_pytorch(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    val_loader: torch.utils.data.DataLoader = None,\n",
    "    loss_fn: torch.nn.Module = None,\n",
    "    optimiser: torch.optim.Optimizer = None,\n",
    "    num_epochs: int = 10,\n",
    ") -> Tuple[List[float], List[float], List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Train the model and log metrics.\n",
    "    Returns:\n",
    "        Tuple of training losses, validation losses, training accuracies, validation accuracies.\n",
    "    \"\"\"\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "\n",
    "    # Create a mapping from old class indices to new class indices\n",
    "    class_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(chosen_classes)}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Starting epoch {epoch + 1}/{num_epochs}.\")\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_train_acc = 0.0\n",
    "        n_train_samples = 0\n",
    "\n",
    "        # Use tqdm for the training loader\n",
    "        train_loop = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Train]\", leave=False)\n",
    "        for b_data, b_labels in train_loop:\n",
    "            n_train_samples += b_data.size(0)\n",
    "            optimiser.zero_grad()\n",
    "            outputs = model(b_data)\n",
    "            # Filter the labels to only include the chosen classes\n",
    "            mask = torch.isin(b_labels, torch.tensor(list(chosen_classes)))\n",
    "            if not mask.any():\n",
    "                continue\n",
    "            filtered_b_labels = b_labels[mask]\n",
    "            # Convert labels to new class indices\n",
    "            filtered_b_labels = torch.tensor([class_mapping[label.item()] for label in filtered_b_labels])\n",
    "            # Convert labels to one-hot encoding with the correct number of classes\n",
    "            b_labels_one_hot = torch.zeros(filtered_b_labels.size(0), len(chosen_classes)).scatter_(1, filtered_b_labels.unsqueeze(1), 1)\n",
    "            # Filter the outputs to only include the chosen classes\n",
    "            outputs = outputs[mask]\n",
    "            loss = loss_fn(outputs, b_labels_one_hot)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            epoch_train_loss += loss.item() * b_data.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            epoch_train_acc += (preds == filtered_b_labels).sum().item()\n",
    "\n",
    "            # Update progress bar with current loss and accuracy\n",
    "            batch_acc = (preds == filtered_b_labels).sum().item() / b_data.size(0)\n",
    "            train_loop.set_postfix(loss=loss.item(), acc=batch_acc)\n",
    "\n",
    "        # Average metrics\n",
    "        epoch_train_loss /= n_train_samples\n",
    "        epoch_train_acc /= n_train_samples\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accs.append(epoch_train_acc)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        if val_loader is not None:\n",
    "            model.eval()\n",
    "            epoch_val_loss = 0.0\n",
    "            epoch_val_acc = 0.0\n",
    "            n_val_samples = 0\n",
    "\n",
    "            # Use tqdm for the validation loader\n",
    "            val_loop = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Val]\", leave=False)\n",
    "            with torch.no_grad():\n",
    "                for b_data, b_labels in val_loop:\n",
    "                    n_val_samples += b_data.size(0)\n",
    "                    outputs = model(b_data)\n",
    "                    # Filter the labels to only include the chosen classes\n",
    "                    mask = torch.isin(b_labels, torch.tensor(list(chosen_classes)))\n",
    "                    if not mask.any():\n",
    "                        continue\n",
    "                    filtered_b_labels = b_labels[mask]\n",
    "                    # Convert labels to new class indices\n",
    "                    filtered_b_labels = torch.tensor([class_mapping[label.item()] for label in filtered_b_labels])\n",
    "                    # Convert labels to one-hot encoding with the correct number of classes\n",
    "                    b_labels_one_hot = torch.zeros(filtered_b_labels.size(0), len(chosen_classes)).scatter_(1, filtered_b_labels.unsqueeze(1), 1)\n",
    "                    # Filter the outputs to only include the chosen classes\n",
    "                    outputs = outputs[mask]\n",
    "                    loss = loss_fn(outputs, b_labels_one_hot)\n",
    "                    epoch_val_loss += loss.item() * b_data.size(0)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    epoch_val_acc += (preds == filtered_b_labels).sum().item()\n",
    "\n",
    "                    # Update progress bar with current loss and accuracy\n",
    "                    batch_acc = (preds == filtered_b_labels).sum().item() / b_data.size(0)\n",
    "                    val_loop.set_postfix(loss=loss.item(), acc=batch_acc)\n",
    "\n",
    "            epoch_val_loss /= n_val_samples\n",
    "            epoch_val_acc /= n_val_samples\n",
    "            val_losses.append(epoch_val_loss)\n",
    "            val_accs.append(epoch_val_acc)\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e04f14-c213-480a-bcdb-9c00ea8c48e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.1278, Train Acc: 0.7169\n",
      "Starting epoch 2/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.0230, Train Acc: 0.9565\n",
      "Starting epoch 3/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.0137, Train Acc: 0.9826\n",
      "Starting epoch 4/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.0103, Train Acc: 0.9875\n",
      "Starting epoch 5/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.0081, Train Acc: 0.9922\n",
      "Starting epoch 6/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.0072, Train Acc: 0.9936\n",
      "Starting epoch 7/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.0061, Train Acc: 0.9948\n",
      "Starting epoch 8/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Loss: 0.0056, Train Acc: 0.9958\n",
      "Starting epoch 9/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Loss: 0.0048, Train Acc: 0.9967\n",
      "Starting epoch 10/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Loss: 0.0044, Train Acc: 0.9979\n",
      "Starting epoch 11/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Loss: 0.0040, Train Acc: 0.9976\n",
      "Starting epoch 12/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Loss: 0.0037, Train Acc: 0.9988\n",
      "Starting epoch 13/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Loss: 0.0034, Train Acc: 0.9984\n",
      "Starting epoch 14/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Loss: 0.0032, Train Acc: 0.9993\n",
      "Starting epoch 15/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Loss: 0.0029, Train Acc: 0.9993\n",
      "Starting epoch 16/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Loss: 0.0028, Train Acc: 0.9993\n",
      "Starting epoch 17/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Loss: 0.0026, Train Acc: 0.9993\n",
      "Starting epoch 18/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Loss: 0.0025, Train Acc: 0.9993\n",
      "Starting epoch 19/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Loss: 0.0023, Train Acc: 0.9993\n",
      "Starting epoch 20/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Loss: 0.0022, Train Acc: 0.9993\n",
      "Starting epoch 21/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Loss: 0.0021, Train Acc: 0.9993\n",
      "Starting epoch 22/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Loss: 0.0020, Train Acc: 0.9995\n",
      "Starting epoch 23/30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 [Train]:  88%|████████▊ | 117/133 [00:02<00:00, 55.58it/s, acc=1, loss=0.00193]   "
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "train_losses, _, train_accs, _ = train_pytorch(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader=None,\n",
    "    loss_fn=loss_fn,\n",
    "    optimiser=optimiser,\n",
    "    num_epochs=30\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb1d6bf-6605-4d8f-951f-3424871a044d",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38390b3a-14b9-427c-bcab-530085131a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    model: torch.nn.Module,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    "    loss_fn: torch.nn.Module,\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test dataset.\n",
    "    Returns:\n",
    "        Tuple of test loss and test accuracy.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    n_test_samples = 0\n",
    "\n",
    "    # Create a mapping from old class indices to new class indices\n",
    "    class_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(chosen_classes)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b_data, b_labels in test_loader:\n",
    "            n_test_samples += b_data.size(0)\n",
    "            outputs = model(b_data)\n",
    "            # Filter the labels to only include the chosen classes\n",
    "            mask = torch.isin(b_labels, torch.tensor(list(chosen_classes)))\n",
    "            if not mask.any():\n",
    "                continue\n",
    "            filtered_b_labels = b_labels[mask]\n",
    "            # Convert labels to new class indices\n",
    "            filtered_b_labels = torch.tensor([class_mapping[label.item()] for label in filtered_b_labels])\n",
    "            # Convert labels to one-hot encoding with the correct number of classes\n",
    "            b_labels_one_hot = torch.zeros(filtered_b_labels.size(0), len(chosen_classes)).scatter_(1, filtered_b_labels.unsqueeze(1), 1)\n",
    "            # Filter the outputs to only include the chosen classes\n",
    "            outputs = outputs[mask]\n",
    "            loss = loss_fn(outputs, b_labels_one_hot)\n",
    "            test_loss += loss.item() * b_data.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_acc += (preds == filtered_b_labels).sum().item()\n",
    "\n",
    "    test_loss /= n_test_samples\n",
    "    test_acc /= n_test_samples\n",
    "\n",
    "    return test_loss, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7797df-ffcf-4e62-bd7d-ccf3acfeeaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = evaluate(model, test_loader, loss_fn)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019764f7-a7d3-46d5-bab4-f86c38c5824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import viz\n",
    "\n",
    "# Plot the loss and accuracy.\n",
    "viz.plot_curves(train_losses, train_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921a01e-613e-48e7-8af3-a3a9d22ccc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "all_true_labels = []\n",
    "all_predictions = []\n",
    "for batch_data, batch_labels in test_loader:\n",
    "    with torch.no_grad():\n",
    "        outputs = model(batch_data)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "    all_true_labels.extend(batch_labels.numpy())\n",
    "    all_predictions.extend(predictions.numpy())\n",
    "\n",
    "# Filter the true labels and predictions to include only the classes of interest.\n",
    "filtered_true_labels = []\n",
    "filtered_predictions = []\n",
    "for true, pred in zip(all_true_labels, all_predictions):\n",
    "    if true in chosen_classes and pred in chosen_classes:\n",
    "        filtered_true_labels.append(true)\n",
    "        filtered_predictions.append(pred)\n",
    "\n",
    "# Plot the confusion matrix using the filtered data.\n",
    "viz.plot_confusion_matrix(\n",
    "    np.array(filtered_true_labels),\n",
    "    np.array(filtered_predictions),\n",
    "    chosen_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d47274-cf7f-4f6b-8ed3-6eba8c33b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compute_saliency_map(model, input_sample):\n",
    "    \"\"\"\n",
    "    Compute the saliency map for a given input sample.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to compute saliency maps for.\n",
    "        input_sample (torch.Tensor): The input sample.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The saliency map.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    input_sample = input_sample.unsqueeze(0)  # Add batch dimension\n",
    "    input_sample.requires_grad_(True)\n",
    "    output = model(input_sample)\n",
    "    # Assuming a classification task, take the class with the highest score\n",
    "    output.max().backward()\n",
    "    saliency_map = input_sample.grad.data.abs().squeeze()\n",
    "    return saliency_map\n",
    "\n",
    "def plot_saliency_map(saliency_map):\n",
    "    \"\"\"\n",
    "    Plot the saliency map.\n",
    "\n",
    "    Args:\n",
    "        saliency_map (torch.Tensor): The saliency map to plot.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    # Normalize the saliency map to the range [0, 1]\n",
    "    saliency_map = saliency_map / saliency_map.max()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(saliency_map, cmap=\"hot\")\n",
    "    plt.colorbar(label=\"Saliency Value\")\n",
    "    plt.title(\"Saliency Map\")\n",
    "    plt.xlabel(\"Width\")\n",
    "    plt.ylabel(\"Height\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b02f2-a449-4106-b53e-20dff34db345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and plot saliency maps for the first sample.\n",
    "input_sample = batch_data[0]\n",
    "saliency_map = compute_saliency_map(model, input_sample)\n",
    "plot_saliency_map(saliency_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f15a5-1d3f-4392-853e-402900efa476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(\n",
    "    model: torch.nn.Module,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute the accuracy of the model on the test dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to evaluate.\n",
    "        test_loader (torch.utils.data.DataLoader): The data loader for the test dataset.\n",
    "\n",
    "    Returns:\n",
    "        float: The accuracy of the model on the test dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_acc = 0.0\n",
    "    n_test_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b_data, b_labels in test_loader:\n",
    "            n_test_samples += b_data.size(0)\n",
    "            outputs = model(b_data)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_acc += (preds == b_labels).sum().item()\n",
    "\n",
    "    test_acc /= n_test_samples\n",
    "\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ef0b63-93ab-4a55-86a9-b275d5b87c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = compute_accuracy(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1af58a4-49e4-4b04-ac10-ab02da39491e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
