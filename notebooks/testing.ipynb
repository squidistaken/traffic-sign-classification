{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a0cbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 16:42:33,750 - INFO - Downloading GTSRB_Final_Training_Images...\n",
      "2025-10-31 16:42:56,967 - INFO - Unpacking GTSRB_Final_Training_Images...\n",
      "2025-10-31 16:43:04,291 - INFO - Downloading GTSRB_Final_Test_Images...\n",
      "2025-10-31 16:43:12,072 - INFO - Unpacking GTSRB_Final_Test_Images...\n",
      "2025-10-31 16:43:14,451 - INFO - Downloading GTSRB_Final_Test_GT...\n",
      "2025-10-31 16:43:14,618 - INFO - Unpacking GTSRB_Final_Test_GT...\n",
      "2025-10-31 16:43:14,623 - INFO - GTSRB data is ready.\n",
      "2025-10-31 16:43:17,894 - INFO - GTSRB data cleaned and organized.\n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "%run \"../dataio/gtsrb_download.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad79e5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/richard/Documents/academics/1a/traffic-sign-classification\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c679b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataio.transforms import ToCompose, ToResize, ToRotate, ToNoise, ToTensor, ToNormalize\n",
    "from dataio.gtsrb_dataset import GTSRBDataset\n",
    "from dataio.dataloader import DataLoader\n",
    "from nn.layers.batchnorm2d import BatchNorm2D\n",
    "from nn.layers.conv2d import Conv2D\n",
    "from nn.layers.dropout import Dropout\n",
    "from nn.layers.flatten import Flatten\n",
    "from nn.layers.linear import Linear\n",
    "from nn.layers.maxpool2d import MaxPool2D\n",
    "from nn.layers.sequential import Sequential\n",
    "from nn.optim import Adam\n",
    "from nn.loss import cross_entropy\n",
    "from train import train\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0ac8db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transforms for training\n",
    "train_transforms = ToCompose([\n",
    "    ToResize(size=64),\n",
    "    ToRotate(angle=15),\n",
    "    ToNoise(mean=0, std=0.05),\n",
    "    ToTensor(),\n",
    "    ToNormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Define the transforms for validation and testing\n",
    "val_transforms = ToCompose([\n",
    "    ToResize(size=64),\n",
    "    ToTensor(),\n",
    "    ToNormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Load Data\n",
    "\n",
    "# %%\n",
    "# Total number of entries in the dataset\n",
    "total_entries = 51840\n",
    "\n",
    "# Define the indices for each split\n",
    "def get_train_indices():\n",
    "    return list(range(int(0.7 * total_entries)))\n",
    "\n",
    "def get_val_indices():\n",
    "    start = int(0.7 * total_entries)\n",
    "    end = int(0.85 * total_entries)\n",
    "    return list(range(start, end))\n",
    "\n",
    "def get_test_indices():\n",
    "    start = int(0.85 * total_entries)\n",
    "    return list(range(start, total_entries))\n",
    "\n",
    "# Initialize the dataset\n",
    "train_dataset = GTSRBDataset(\n",
    "    root=\"./data/gtsrb/\",\n",
    "    indices=get_train_indices(),\n",
    "    split=\"train\",\n",
    "    transforms=train_transforms\n",
    ")\n",
    "val_dataset = GTSRBDataset(\n",
    "    root=\"./data/gtsrb/\",\n",
    "    indices=get_val_indices(),\n",
    "    split=\"val\",\n",
    "    transforms=val_transforms\n",
    ")\n",
    "test_dataset = GTSRBDataset(\n",
    "    root=\"./data/gtsrb/\",\n",
    "    indices=get_test_indices(),\n",
    "    split=\"test\",\n",
    "    transforms=val_transforms\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acf306bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example architecture without ReLU\n",
    "layers = [\n",
    "    Conv2D(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "    BatchNorm2D(num_channels=32),\n",
    "    MaxPool2D(pool_size=2, stride=2),\n",
    "    Conv2D(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "    BatchNorm2D(num_channels=64),\n",
    "    MaxPool2D(pool_size=2, stride=2),\n",
    "    Conv2D(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "    BatchNorm2D(num_channels=128),\n",
    "    MaxPool2D(pool_size=2, stride=2),\n",
    "    Flatten(),\n",
    "    Linear(in_features=128 * 8 * 8, out_features=512),  # Adjust input_size based on your image size and pooling layers\n",
    "    Dropout(p=0.5),\n",
    "    Linear(in_features=512, out_features=43)  # GTSRB has 43 classes\n",
    "]\n",
    "\n",
    "model = Sequential(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4e3cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the parameters from the model\n",
    "params = []\n",
    "for layer in model.layers:\n",
    "    param_list = layer.params()\n",
    "    for name, param in param_list:\n",
    "        params.append((layer, name, param))\n",
    "\n",
    "# Initialize the optimizer (e.g., SGD, Adam, or Momentum)\n",
    "optimizer = Adam(params, lr=0.001)  # Example using Adam optimizer\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9991524b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train the model using the train function\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_losses, val_losses, train_accs, val_accs = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\train.py:44\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_loader, val_loader, loss_fn, optimiser, num_epochs, batch_size, checkpoint_dir, log_dir)\u001b[39m\n\u001b[32m     41\u001b[39m output = model.forward(b_data, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Loss and gradient\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m loss, grad_output = loss_fn(output, b_labels)\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m     47\u001b[39m model.backward(grad_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\nn\\layers\\sequential.py:45\u001b[39m, in \u001b[36mSequential.backward\u001b[39m\u001b[34m(self, dout)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[33;03mPerform the backward pass of the layer.\u001b[39;00m\n\u001b[32m     37\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m \u001b[33;03m    np.ndarray: The downstream gradient.\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m.layers):\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     dout = \u001b[43mlayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dout\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\nn\\layers\\maxpool2d.py:94\u001b[39m, in \u001b[36mMaxPool2D.backward\u001b[39m\u001b[34m(self, dout)\u001b[39m\n\u001b[32m     92\u001b[39m window = cols_reshaped[n, c, i, j]  \u001b[38;5;66;03m# shape = (pool_h, pool_w)\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# Find the position of the max in the window\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m max_idx = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43munravel_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# Add the gradient to the corresponding input position\u001b[39;00m\n\u001b[32m     96\u001b[39m h_start = i * stride\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model using the train function\n",
    "train_losses, val_losses, train_accs, val_accs = train(\n",
    "    model, train_loader, val_loader, loss_fn, optimizer, num_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e59078-fd11-4c3c-9310-9c6375ee1569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic-sign-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
