{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a0cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "%run \"../dataio/gtsrb_download.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad79e5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marcusp/Documents/traffic-sign-classification\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c679b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataio.transforms import ToCompose, ToResize, ToRotate, ToNoise, ToTensor, ToNormalize\n",
    "from dataio.gtsrb_dataset import GTSRBDataset\n",
    "from dataio.dataloader import DataLoader\n",
    "from nn.layers.batchnorm2d import BatchNorm2D\n",
    "from nn.layers.conv2d import Conv2D\n",
    "from nn.layers.dropout import Dropout\n",
    "from nn.layers.flatten import Flatten\n",
    "from nn.layers.linear import Linear\n",
    "from nn.layers.maxpool2d import MaxPool2D\n",
    "from nn.layers.sequential import Sequential\n",
    "from nn.optim import Adam\n",
    "from nn.loss import cross_entropy\n",
    "from train import train\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0ac8db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transforms for training\n",
    "train_transforms = ToCompose([\n",
    "    ToResize(size=64),\n",
    "    ToRotate(angle=15),\n",
    "    ToNoise(mean=0, std=0.05),\n",
    "    ToTensor(),\n",
    "    ToNormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Define the transforms for validation and testing\n",
    "val_transforms = ToCompose([\n",
    "    ToResize(size=64),\n",
    "    ToTensor(),\n",
    "    ToNormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Total number of entries in the dataset\n",
    "total_entries = 51839\n",
    "\n",
    "# Define the indices for each split\n",
    "def get_train_indices():\n",
    "    return list(range(int(0.7 * total_entries)))\n",
    "\n",
    "def get_val_indices():\n",
    "    start = int(0.7 * total_entries)\n",
    "    end = int(0.85 * total_entries)\n",
    "    return list(range(start, end))\n",
    "\n",
    "def get_test_indices():\n",
    "    start = int(0.85 * total_entries)\n",
    "    return list(range(start, total_entries))\n",
    "\n",
    "# Initialize the dataset\n",
    "train_dataset = GTSRBDataset(\n",
    "    root=\"./data/gtsrb/\",\n",
    "    indices=get_train_indices(),\n",
    "    split=\"train\",\n",
    "    transforms=train_transforms\n",
    ")\n",
    "val_dataset = GTSRBDataset(\n",
    "    root=\"./data/gtsrb/\",\n",
    "    indices=get_val_indices(),\n",
    "    split=\"val\",\n",
    "    transforms=val_transforms\n",
    ")\n",
    "test_dataset = GTSRBDataset(\n",
    "    root=\"./data/gtsrb/\",\n",
    "    indices=get_test_indices(),\n",
    "    split=\"test\",\n",
    "    transforms=val_transforms\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acf306bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example architecture without ReLU\n",
    "layers = [\n",
    "    Conv2D(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "    BatchNorm2D(num_channels=32),\n",
    "    MaxPool2D(pool_size=2, stride=2),\n",
    "    Conv2D(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "    BatchNorm2D(num_channels=64),\n",
    "    MaxPool2D(pool_size=2, stride=2),\n",
    "    Conv2D(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "    BatchNorm2D(num_channels=128),\n",
    "    MaxPool2D(pool_size=2, stride=2),\n",
    "    Flatten(),\n",
    "    Linear(in_features=128 * 8 * 8, out_features=512),  # Adjust input_size based on your image size and pooling layers\n",
    "    Dropout(p=0.5),\n",
    "    Linear(in_features=512, out_features=43)  # GTSRB has 43 classes\n",
    "]\n",
    "\n",
    "model = Sequential(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4e3cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the parameters from the model\n",
    "params = []\n",
    "for layer in model.layers:\n",
    "    param_list = layer.params()\n",
    "    for name, param in param_list:\n",
    "        params.append((layer, name, param))\n",
    "\n",
    "# Initialize the optimizer (e.g., SGD, Adam, or Momentum)\n",
    "optimizer = Adam(params, lr=0.001)  # Example using Adam optimizer\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9991524b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 19:41:36,613 - DEBUG - Training started.\n",
      "2025-10-31 19:41:36,613 - root - DEBUG - Training started.\n",
      "2025-10-31 19:41:36,613 - root - DEBUG - Training started.\n",
      "2025-10-31 19:41:36,615 - DEBUG - Starting epoch 1/10.\n",
      "2025-10-31 19:41:36,615 - root - DEBUG - Starting epoch 1/10.\n",
      "2025-10-31 19:41:36,615 - root - DEBUG - Starting epoch 1/10.\n",
      "2025-10-31 19:41:36,662 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:41:36,662 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:41:36,662 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:41:40,752 - DEBUG - Training batch loss: 7.124588340295551\n",
      "2025-10-31 19:41:40,752 - root - DEBUG - Training batch loss: 7.124588340295551\n",
      "2025-10-31 19:41:40,752 - root - DEBUG - Training batch loss: 7.124588340295551\n",
      "2025-10-31 19:41:44,332 - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:41:44,332 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:41:44,332 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:41:44,334 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:41:44,334 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:41:44,334 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:41:48,340 - DEBUG - Training batch loss: 15.350515530769117\n",
      "2025-10-31 19:41:48,340 - root - DEBUG - Training batch loss: 15.350515530769117\n",
      "2025-10-31 19:41:48,340 - root - DEBUG - Training batch loss: 15.350515530769117\n",
      "2025-10-31 19:41:51,889 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:41:51,889 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:41:51,889 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:41:51,891 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:41:51,891 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:41:51,891 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:41:55,636 - DEBUG - Training batch loss: 22.87962456521732\n",
      "2025-10-31 19:41:55,636 - root - DEBUG - Training batch loss: 22.87962456521732\n",
      "2025-10-31 19:41:55,636 - root - DEBUG - Training batch loss: 22.87962456521732\n",
      "2025-10-31 19:41:58,922 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:41:58,922 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:41:58,922 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:41:58,924 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:41:58,924 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:41:58,924 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:02,583 - DEBUG - Training batch loss: 14.57334639756595\n",
      "2025-10-31 19:42:02,583 - root - DEBUG - Training batch loss: 14.57334639756595\n",
      "2025-10-31 19:42:02,583 - root - DEBUG - Training batch loss: 14.57334639756595\n",
      "2025-10-31 19:42:05,799 - DEBUG - Training batch accuracy: 0.125\n",
      "2025-10-31 19:42:05,799 - root - DEBUG - Training batch accuracy: 0.125\n",
      "2025-10-31 19:42:05,799 - root - DEBUG - Training batch accuracy: 0.125\n",
      "2025-10-31 19:42:05,801 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:05,801 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:05,801 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:09,667 - DEBUG - Training batch loss: 16.806081330782103\n",
      "2025-10-31 19:42:09,667 - root - DEBUG - Training batch loss: 16.806081330782103\n",
      "2025-10-31 19:42:09,667 - root - DEBUG - Training batch loss: 16.806081330782103\n",
      "2025-10-31 19:42:12,973 - DEBUG - Training batch accuracy: 0.09375\n",
      "2025-10-31 19:42:12,973 - root - DEBUG - Training batch accuracy: 0.09375\n",
      "2025-10-31 19:42:12,973 - root - DEBUG - Training batch accuracy: 0.09375\n",
      "2025-10-31 19:42:12,975 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:12,975 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:12,975 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:16,691 - DEBUG - Training batch loss: 19.857292687224643\n",
      "2025-10-31 19:42:16,691 - root - DEBUG - Training batch loss: 19.857292687224643\n",
      "2025-10-31 19:42:16,691 - root - DEBUG - Training batch loss: 19.857292687224643\n",
      "2025-10-31 19:42:20,037 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:42:20,037 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:42:20,037 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:42:20,039 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:20,039 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:20,039 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:23,922 - DEBUG - Training batch loss: 18.818279933866958\n",
      "2025-10-31 19:42:23,922 - root - DEBUG - Training batch loss: 18.818279933866958\n",
      "2025-10-31 19:42:23,922 - root - DEBUG - Training batch loss: 18.818279933866958\n",
      "2025-10-31 19:42:27,079 - DEBUG - Training batch accuracy: 0.09375\n",
      "2025-10-31 19:42:27,079 - root - DEBUG - Training batch accuracy: 0.09375\n",
      "2025-10-31 19:42:27,079 - root - DEBUG - Training batch accuracy: 0.09375\n",
      "2025-10-31 19:42:27,081 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:27,081 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:27,081 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:30,890 - DEBUG - Training batch loss: 20.16877226032834\n",
      "2025-10-31 19:42:30,890 - root - DEBUG - Training batch loss: 20.16877226032834\n",
      "2025-10-31 19:42:30,890 - root - DEBUG - Training batch loss: 20.16877226032834\n",
      "2025-10-31 19:42:34,346 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:42:34,346 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:42:34,346 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:42:34,348 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:34,348 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:34,348 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:38,279 - DEBUG - Training batch loss: 22.318041361334295\n",
      "2025-10-31 19:42:38,279 - root - DEBUG - Training batch loss: 22.318041361334295\n",
      "2025-10-31 19:42:38,279 - root - DEBUG - Training batch loss: 22.318041361334295\n",
      "2025-10-31 19:42:41,858 - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:42:41,858 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:42:41,858 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:42:41,860 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:41,860 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:41,860 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:45,572 - DEBUG - Training batch loss: 22.014599897882455\n",
      "2025-10-31 19:42:45,572 - root - DEBUG - Training batch loss: 22.014599897882455\n",
      "2025-10-31 19:42:45,572 - root - DEBUG - Training batch loss: 22.014599897882455\n",
      "2025-10-31 19:42:48,636 - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:42:48,636 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:42:48,636 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:42:48,638 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:48,638 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:48,638 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:52,103 - DEBUG - Training batch loss: 17.678910014411603\n",
      "2025-10-31 19:42:52,103 - root - DEBUG - Training batch loss: 17.678910014411603\n",
      "2025-10-31 19:42:52,103 - root - DEBUG - Training batch loss: 17.678910014411603\n",
      "2025-10-31 19:42:55,130 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:42:55,130 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:42:55,130 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:42:55,132 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:55,132 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:55,132 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:42:58,593 - DEBUG - Training batch loss: 22.904034634371463\n",
      "2025-10-31 19:42:58,593 - root - DEBUG - Training batch loss: 22.904034634371463\n",
      "2025-10-31 19:42:58,593 - root - DEBUG - Training batch loss: 22.904034634371463\n",
      "2025-10-31 19:43:01,821 - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:43:01,821 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:43:01,821 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:43:01,822 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:01,822 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:01,822 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:05,897 - DEBUG - Training batch loss: 26.283152021477807\n",
      "2025-10-31 19:43:05,897 - root - DEBUG - Training batch loss: 26.283152021477807\n",
      "2025-10-31 19:43:05,897 - root - DEBUG - Training batch loss: 26.283152021477807\n",
      "2025-10-31 19:43:09,673 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:43:09,673 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:43:09,673 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:43:09,676 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:09,676 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:09,676 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:13,597 - DEBUG - Training batch loss: 21.179934019419477\n",
      "2025-10-31 19:43:13,597 - root - DEBUG - Training batch loss: 21.179934019419477\n",
      "2025-10-31 19:43:13,597 - root - DEBUG - Training batch loss: 21.179934019419477\n",
      "2025-10-31 19:43:16,992 - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:43:16,992 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:43:16,992 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:43:16,995 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:16,995 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:16,995 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:20,907 - DEBUG - Training batch loss: 22.56802333978225\n",
      "2025-10-31 19:43:20,907 - root - DEBUG - Training batch loss: 22.56802333978225\n",
      "2025-10-31 19:43:20,907 - root - DEBUG - Training batch loss: 22.56802333978225\n",
      "2025-10-31 19:43:24,113 - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:43:24,113 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:43:24,113 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:43:24,115 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:24,115 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:24,115 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:28,130 - DEBUG - Training batch loss: 18.24502266971797\n",
      "2025-10-31 19:43:28,130 - root - DEBUG - Training batch loss: 18.24502266971797\n",
      "2025-10-31 19:43:28,130 - root - DEBUG - Training batch loss: 18.24502266971797\n",
      "2025-10-31 19:43:31,245 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:43:31,245 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:43:31,245 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:43:31,247 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:31,247 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:31,247 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:34,909 - DEBUG - Training batch loss: 18.4176674495846\n",
      "2025-10-31 19:43:34,909 - root - DEBUG - Training batch loss: 18.4176674495846\n",
      "2025-10-31 19:43:34,909 - root - DEBUG - Training batch loss: 18.4176674495846\n",
      "2025-10-31 19:43:38,224 - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:43:38,224 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:43:38,224 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:43:38,226 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:38,226 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:38,226 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:41,974 - DEBUG - Training batch loss: 18.371669749768337\n",
      "2025-10-31 19:43:41,974 - root - DEBUG - Training batch loss: 18.371669749768337\n",
      "2025-10-31 19:43:41,974 - root - DEBUG - Training batch loss: 18.371669749768337\n",
      "2025-10-31 19:43:45,324 - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:43:45,324 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:43:45,324 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:43:45,325 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:45,325 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:45,325 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:48,995 - DEBUG - Training batch loss: 22.35971870503429\n",
      "2025-10-31 19:43:48,995 - root - DEBUG - Training batch loss: 22.35971870503429\n",
      "2025-10-31 19:43:48,995 - root - DEBUG - Training batch loss: 22.35971870503429\n",
      "2025-10-31 19:43:52,186 - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:43:52,186 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:43:52,186 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:43:52,188 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:52,188 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:52,188 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:55,908 - DEBUG - Training batch loss: 23.73189685366536\n",
      "2025-10-31 19:43:55,908 - root - DEBUG - Training batch loss: 23.73189685366536\n",
      "2025-10-31 19:43:55,908 - root - DEBUG - Training batch loss: 23.73189685366536\n",
      "2025-10-31 19:43:59,058 - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:43:59,058 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:43:59,058 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:43:59,059 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:59,059 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:43:59,059 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:02,861 - DEBUG - Training batch loss: 25.343672847553847\n",
      "2025-10-31 19:44:02,861 - root - DEBUG - Training batch loss: 25.343672847553847\n",
      "2025-10-31 19:44:02,861 - root - DEBUG - Training batch loss: 25.343672847553847\n",
      "2025-10-31 19:44:05,956 - DEBUG - Training batch accuracy: 0.09375\n",
      "2025-10-31 19:44:05,956 - root - DEBUG - Training batch accuracy: 0.09375\n",
      "2025-10-31 19:44:05,956 - root - DEBUG - Training batch accuracy: 0.09375\n",
      "2025-10-31 19:44:05,958 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:05,958 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:05,958 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:09,592 - DEBUG - Training batch loss: 24.736430375705673\n",
      "2025-10-31 19:44:09,592 - root - DEBUG - Training batch loss: 24.736430375705673\n",
      "2025-10-31 19:44:09,592 - root - DEBUG - Training batch loss: 24.736430375705673\n",
      "2025-10-31 19:44:12,892 - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:44:12,892 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:44:12,892 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:44:12,894 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:12,894 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:12,894 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:16,901 - DEBUG - Training batch loss: 23.223138114010922\n",
      "2025-10-31 19:44:16,901 - root - DEBUG - Training batch loss: 23.223138114010922\n",
      "2025-10-31 19:44:16,901 - root - DEBUG - Training batch loss: 23.223138114010922\n",
      "2025-10-31 19:44:20,823 - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:44:20,823 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:44:20,823 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:44:20,824 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:20,824 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:20,824 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:24,705 - DEBUG - Training batch loss: 22.021079144500092\n",
      "2025-10-31 19:44:24,705 - root - DEBUG - Training batch loss: 22.021079144500092\n",
      "2025-10-31 19:44:24,705 - root - DEBUG - Training batch loss: 22.021079144500092\n",
      "2025-10-31 19:44:28,276 - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:44:28,276 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:44:28,276 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:44:28,277 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:28,277 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:28,277 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:31,897 - DEBUG - Training batch loss: 21.82471421098618\n",
      "2025-10-31 19:44:31,897 - root - DEBUG - Training batch loss: 21.82471421098618\n",
      "2025-10-31 19:44:31,897 - root - DEBUG - Training batch loss: 21.82471421098618\n",
      "2025-10-31 19:44:35,147 - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:44:35,147 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:44:35,147 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:44:35,148 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:35,148 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:35,148 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:39,095 - DEBUG - Training batch loss: 20.498159839285485\n",
      "2025-10-31 19:44:39,095 - root - DEBUG - Training batch loss: 20.498159839285485\n",
      "2025-10-31 19:44:39,095 - root - DEBUG - Training batch loss: 20.498159839285485\n",
      "2025-10-31 19:44:42,493 - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:44:42,493 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:44:42,493 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:44:42,495 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:42,495 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:42,495 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:46,493 - DEBUG - Training batch loss: 22.376627823595125\n",
      "2025-10-31 19:44:46,493 - root - DEBUG - Training batch loss: 22.376627823595125\n",
      "2025-10-31 19:44:46,493 - root - DEBUG - Training batch loss: 22.376627823595125\n",
      "2025-10-31 19:44:49,833 - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:44:49,833 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:44:49,833 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:44:49,835 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:49,835 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:49,835 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:53,399 - DEBUG - Training batch loss: 18.97755089707694\n",
      "2025-10-31 19:44:53,399 - root - DEBUG - Training batch loss: 18.97755089707694\n",
      "2025-10-31 19:44:53,399 - root - DEBUG - Training batch loss: 18.97755089707694\n",
      "2025-10-31 19:44:56,982 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:44:56,982 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:44:56,982 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:44:56,984 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:56,984 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:44:56,984 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:00,693 - DEBUG - Training batch loss: 15.364659396741875\n",
      "2025-10-31 19:45:00,693 - root - DEBUG - Training batch loss: 15.364659396741875\n",
      "2025-10-31 19:45:00,693 - root - DEBUG - Training batch loss: 15.364659396741875\n",
      "2025-10-31 19:45:03,779 - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:45:03,779 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:45:03,779 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:45:03,781 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:03,781 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:03,781 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:07,722 - DEBUG - Training batch loss: 18.816842757330274\n",
      "2025-10-31 19:45:07,722 - root - DEBUG - Training batch loss: 18.816842757330274\n",
      "2025-10-31 19:45:07,722 - root - DEBUG - Training batch loss: 18.816842757330274\n",
      "2025-10-31 19:45:10,875 - DEBUG - Training batch accuracy: 0.09375\n",
      "2025-10-31 19:45:10,875 - root - DEBUG - Training batch accuracy: 0.09375\n",
      "2025-10-31 19:45:10,875 - root - DEBUG - Training batch accuracy: 0.09375\n",
      "2025-10-31 19:45:10,877 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:10,877 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:10,877 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:14,538 - DEBUG - Training batch loss: 19.07652372383806\n",
      "2025-10-31 19:45:14,538 - root - DEBUG - Training batch loss: 19.07652372383806\n",
      "2025-10-31 19:45:14,538 - root - DEBUG - Training batch loss: 19.07652372383806\n",
      "2025-10-31 19:45:17,722 - DEBUG - Training batch accuracy: 0.1875\n",
      "2025-10-31 19:45:17,722 - root - DEBUG - Training batch accuracy: 0.1875\n",
      "2025-10-31 19:45:17,722 - root - DEBUG - Training batch accuracy: 0.1875\n",
      "2025-10-31 19:45:17,724 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:17,724 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:17,724 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:21,865 - DEBUG - Training batch loss: 15.602452921679053\n",
      "2025-10-31 19:45:21,865 - root - DEBUG - Training batch loss: 15.602452921679053\n",
      "2025-10-31 19:45:21,865 - root - DEBUG - Training batch loss: 15.602452921679053\n",
      "2025-10-31 19:45:25,311 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:45:25,311 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:45:25,311 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:45:25,312 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:25,312 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:25,312 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:29,283 - DEBUG - Training batch loss: 19.257954707976317\n",
      "2025-10-31 19:45:29,283 - root - DEBUG - Training batch loss: 19.257954707976317\n",
      "2025-10-31 19:45:29,283 - root - DEBUG - Training batch loss: 19.257954707976317\n",
      "2025-10-31 19:45:32,794 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:45:32,794 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:45:32,794 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:45:32,796 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:32,796 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:32,796 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:36,832 - DEBUG - Training batch loss: 19.196576232825066\n",
      "2025-10-31 19:45:36,832 - root - DEBUG - Training batch loss: 19.196576232825066\n",
      "2025-10-31 19:45:36,832 - root - DEBUG - Training batch loss: 19.196576232825066\n",
      "2025-10-31 19:45:40,236 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:45:40,236 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:45:40,236 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:45:40,238 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:40,238 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:40,238 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:44,302 - DEBUG - Training batch loss: 12.989678149864503\n",
      "2025-10-31 19:45:44,302 - root - DEBUG - Training batch loss: 12.989678149864503\n",
      "2025-10-31 19:45:44,302 - root - DEBUG - Training batch loss: 12.989678149864503\n",
      "2025-10-31 19:45:47,718 - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:45:47,718 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:45:47,718 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:45:47,720 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:47,720 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:47,720 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:51,808 - DEBUG - Training batch loss: 16.303927771295385\n",
      "2025-10-31 19:45:51,808 - root - DEBUG - Training batch loss: 16.303927771295385\n",
      "2025-10-31 19:45:51,808 - root - DEBUG - Training batch loss: 16.303927771295385\n",
      "2025-10-31 19:45:55,181 - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:45:55,181 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:45:55,181 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:45:55,183 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:55,183 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:55,183 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:45:59,223 - DEBUG - Training batch loss: 22.51303530923019\n",
      "2025-10-31 19:45:59,223 - root - DEBUG - Training batch loss: 22.51303530923019\n",
      "2025-10-31 19:45:59,223 - root - DEBUG - Training batch loss: 22.51303530923019\n",
      "2025-10-31 19:46:02,507 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:46:02,507 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:46:02,507 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:46:02,510 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:02,510 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:02,510 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:06,436 - DEBUG - Training batch loss: 16.632317588660865\n",
      "2025-10-31 19:46:06,436 - root - DEBUG - Training batch loss: 16.632317588660865\n",
      "2025-10-31 19:46:06,436 - root - DEBUG - Training batch loss: 16.632317588660865\n",
      "2025-10-31 19:46:09,661 - DEBUG - Training batch accuracy: 0.09375\n",
      "2025-10-31 19:46:09,661 - root - DEBUG - Training batch accuracy: 0.09375\n",
      "2025-10-31 19:46:09,661 - root - DEBUG - Training batch accuracy: 0.09375\n",
      "2025-10-31 19:46:09,663 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:09,663 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:09,663 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:13,682 - DEBUG - Training batch loss: 21.520294048786706\n",
      "2025-10-31 19:46:13,682 - root - DEBUG - Training batch loss: 21.520294048786706\n",
      "2025-10-31 19:46:13,682 - root - DEBUG - Training batch loss: 21.520294048786706\n",
      "2025-10-31 19:46:17,136 - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:46:17,136 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:46:17,136 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:46:17,138 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:17,138 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:17,138 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:21,267 - DEBUG - Training batch loss: 16.662215152673202\n",
      "2025-10-31 19:46:21,267 - root - DEBUG - Training batch loss: 16.662215152673202\n",
      "2025-10-31 19:46:21,267 - root - DEBUG - Training batch loss: 16.662215152673202\n",
      "2025-10-31 19:46:24,988 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:46:24,988 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:46:24,988 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:46:24,990 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:24,990 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:24,990 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:29,080 - DEBUG - Training batch loss: 17.831689354717952\n",
      "2025-10-31 19:46:29,080 - root - DEBUG - Training batch loss: 17.831689354717952\n",
      "2025-10-31 19:46:29,080 - root - DEBUG - Training batch loss: 17.831689354717952\n",
      "2025-10-31 19:46:32,518 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:46:32,518 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:46:32,518 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:46:32,520 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:32,520 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:32,520 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:36,707 - DEBUG - Training batch loss: 16.13641012297044\n",
      "2025-10-31 19:46:36,707 - root - DEBUG - Training batch loss: 16.13641012297044\n",
      "2025-10-31 19:46:36,707 - root - DEBUG - Training batch loss: 16.13641012297044\n",
      "2025-10-31 19:46:39,812 - DEBUG - Training batch accuracy: 0.125\n",
      "2025-10-31 19:46:39,812 - root - DEBUG - Training batch accuracy: 0.125\n",
      "2025-10-31 19:46:39,812 - root - DEBUG - Training batch accuracy: 0.125\n",
      "2025-10-31 19:46:39,813 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:39,813 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:39,813 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:43,855 - DEBUG - Training batch loss: 22.93899435859263\n",
      "2025-10-31 19:46:43,855 - root - DEBUG - Training batch loss: 22.93899435859263\n",
      "2025-10-31 19:46:43,855 - root - DEBUG - Training batch loss: 22.93899435859263\n",
      "2025-10-31 19:46:46,979 - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:46:46,979 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:46:46,979 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:46:46,981 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:46,981 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:46,981 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:50,580 - DEBUG - Training batch loss: 26.16217427675874\n",
      "2025-10-31 19:46:50,580 - root - DEBUG - Training batch loss: 26.16217427675874\n",
      "2025-10-31 19:46:50,580 - root - DEBUG - Training batch loss: 26.16217427675874\n",
      "2025-10-31 19:46:54,136 - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:46:54,136 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:46:54,136 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-10-31 19:46:54,138 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:54,138 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:54,138 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:46:57,928 - DEBUG - Training batch loss: 24.058530325407517\n",
      "2025-10-31 19:46:57,928 - root - DEBUG - Training batch loss: 24.058530325407517\n",
      "2025-10-31 19:46:57,928 - root - DEBUG - Training batch loss: 24.058530325407517\n",
      "2025-10-31 19:47:01,541 - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:47:01,541 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:47:01,541 - root - DEBUG - Training batch accuracy: 0.0\n",
      "2025-10-31 19:47:01,543 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:47:01,543 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:47:01,543 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:47:05,635 - DEBUG - Training batch loss: 17.82490561796736\n",
      "2025-10-31 19:47:05,635 - root - DEBUG - Training batch loss: 17.82490561796736\n",
      "2025-10-31 19:47:05,635 - root - DEBUG - Training batch loss: 17.82490561796736\n",
      "2025-10-31 19:47:09,000 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:47:09,000 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:47:09,000 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:47:09,001 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:47:09,001 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:47:09,001 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:47:13,116 - DEBUG - Training batch loss: 17.428226826442156\n",
      "2025-10-31 19:47:13,116 - root - DEBUG - Training batch loss: 17.428226826442156\n",
      "2025-10-31 19:47:13,116 - root - DEBUG - Training batch loss: 17.428226826442156\n",
      "2025-10-31 19:47:16,321 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:47:16,321 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:47:16,321 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-10-31 19:47:16,322 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:47:16,322 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-10-31 19:47:16,322 - root - DEBUG - Processing training batch with 32 samples.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model using the train function\n",
    "train_losses, val_losses, train_accs, val_accs = train(\n",
    "    model, train_loader, val_loader, loss_fn, optimizer, num_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e59078-fd11-4c3c-9310-9c6375ee1569",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_losses)\n",
    "print(val_losses)\n",
    "print(train_accs)\n",
    "print(val_accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
