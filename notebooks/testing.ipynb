{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a0cbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 14:24:16,914 - INFO - Downloading GTSRB_Final_Training_Images...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\dataio\\gtsrb_download.py:183\u001b[39m\n\u001b[32m    179\u001b[39m     logging.info(\u001b[33m\"\u001b[39m\u001b[33mGTSRB data cleaned and organized.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m     clean_data()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\dataio\\gtsrb_download.py:90\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(force_redownload, keep_zips)\u001b[39m\n\u001b[32m     87\u001b[39m     os.makedirs(DATA_DIR)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m zip_name \u001b[38;5;129;01min\u001b[39;00m ZIPS:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[43mensure_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_redownload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep_zips:\n\u001b[32m     92\u001b[39m         delete_zip(zip_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\dataio\\gtsrb_download.py:61\u001b[39m, in \u001b[36mensure_data\u001b[39m\u001b[34m(name, force_redownload)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(DATA_DIR + name) \u001b[38;5;129;01mor\u001b[39;00m force_redownload:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isfile(DATA_DIR + name + \u001b[33m\"\u001b[39m\u001b[33m.zip\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m force_redownload:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m         \u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m     unpack(name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\dataio\\gtsrb_download.py:30\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m     27\u001b[39m logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m url = BASE_URL + name + \u001b[33m\"\u001b[39m\u001b[33m.zip\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(DATA_DIR + name + \u001b[33m\"\u001b[39m\u001b[33m.zip\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     33\u001b[39m     f.write(response.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\anaconda3\\envs\\rl_4\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\anaconda3\\envs\\rl_4\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\anaconda3\\envs\\rl_4\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\anaconda3\\envs\\rl_4\\Lib\\site-packages\\requests\\sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\anaconda3\\envs\\rl_4\\Lib\\site-packages\\requests\\models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\anaconda3\\envs\\rl_4\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\anaconda3\\envs\\rl_4\\Lib\\site-packages\\urllib3\\response.py:1091\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1093\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1094\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\anaconda3\\envs\\rl_4\\Lib\\site-packages\\urllib3\\response.py:980\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    977\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    978\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\anaconda3\\envs\\rl_4\\Lib\\site-packages\\urllib3\\response.py:904\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    901\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    906\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    912\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\anaconda3\\envs\\rl_4\\Lib\\site-packages\\urllib3\\response.py:887\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    884\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    886\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\anaconda3\\envs\\rl_4\\Lib\\http\\client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\anaconda3\\envs\\rl_4\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\anaconda3\\envs\\rl_4\\Lib\\ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\anaconda3\\envs\\rl_4\\Lib\\ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "%run \"../dataio/gtsrb_download.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad79e5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\n"
     ]
    }
   ],
   "source": [
    "# Hard coded because I can't be bothered to make it dynamic LMAO\n",
    "%cd c:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c679b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataio.transforms import ToCompose, ToResize, ToRotate, ToNoise, ToTensor, ToNormalize\n",
    "from dataio.gtsrb_dataset import GTSRBDataset\n",
    "from dataio.dataloader import DataLoader\n",
    "from nn.layers.batchnorm2d import BatchNorm2D\n",
    "from nn.layers.conv2d import Conv2D\n",
    "from nn.layers.dropout import Dropout\n",
    "from nn.layers.flatten import Flatten\n",
    "from nn.layers.linear import Linear\n",
    "from nn.layers.maxpool2d import MaxPool2D\n",
    "from nn.layers.sequential import Sequential\n",
    "from nn.optim import Adam\n",
    "from nn.loss import cross_entropy\n",
    "from train import train\n",
    "from crossval import cross_validate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0ac8db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transforms for training\n",
    "train_transforms = ToCompose([\n",
    "    ToResize(size=64),\n",
    "    ToRotate(angle=15),\n",
    "    ToNoise(mean=0, std=0.05),\n",
    "    ToTensor(),\n",
    "    ToNormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Define the transforms for validation and testing\n",
    "val_transforms = ToCompose([\n",
    "    ToResize(size=64),\n",
    "    ToTensor(),\n",
    "    ToNormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Load Data\n",
    "\n",
    "# %%\n",
    "# Total number of entries in the dataset\n",
    "total_entries = 51840\n",
    "\n",
    "# Define the indices for each split\n",
    "def get_train_indices():\n",
    "    return list(range(int(0.01 * total_entries)))\n",
    "\n",
    "def get_val_indices():\n",
    "    start = int(0.7 * total_entries)\n",
    "    end = int(0.85 * total_entries)\n",
    "    return list(range(start, end))\n",
    "\n",
    "def get_test_indices():\n",
    "    start = int(0.85 * total_entries)\n",
    "    return list(range(start, total_entries))\n",
    "\n",
    "# Initialize the dataset\n",
    "train_dataset = GTSRBDataset(\n",
    "    root=\"./data/gtsrb/\",\n",
    "    indices=get_train_indices(),\n",
    "    split=\"train\",\n",
    "    transforms=train_transforms\n",
    ")\n",
    "val_dataset = GTSRBDataset(\n",
    "    root=\"./data/gtsrb/\",\n",
    "    indices=get_val_indices(),\n",
    "    split=\"val\",\n",
    "    transforms=val_transforms\n",
    ")\n",
    "test_dataset = GTSRBDataset(\n",
    "    root=\"./data/gtsrb/\",\n",
    "    indices=get_test_indices(),\n",
    "    split=\"test\",\n",
    "    transforms=val_transforms\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf306bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example architecture without ReLU\n",
    "layers = [\n",
    "    Conv2D(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "    BatchNorm2D(num_channels=32),\n",
    "    MaxPool2D(pool_size=2, stride=2),\n",
    "    Conv2D(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "    BatchNorm2D(num_channels=64),\n",
    "    MaxPool2D(pool_size=2, stride=2),\n",
    "    Conv2D(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "    BatchNorm2D(num_channels=128),\n",
    "    MaxPool2D(pool_size=2, stride=2),\n",
    "    Flatten(),\n",
    "    Linear(in_features=128 * 8 * 8, out_features=512),  # Adjust input_size based on your image size and pooling layers\n",
    "    Dropout(p=0.5),\n",
    "    Linear(in_features=512, out_features=43)  # GTSRB has 43 classes\n",
    "]\n",
    "\n",
    "model = Sequential(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3cb75",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m         params.append((layer, name, param))\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Initialize optimizer (example: Adam)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m optimizer = \u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Define the loss function\u001b[39;00m\n\u001b[32m     11\u001b[39m loss_fn = cross_entropy\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\nn\\optim.py:24\u001b[39m, in \u001b[36mOptimizer.__init__\u001b[39m\u001b[34m(self, raw_params, lr, weight_decay)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     13\u001b[39m     raw_params: Dict[\u001b[38;5;28mstr\u001b[39m, np.ndarray],\n\u001b[32m     14\u001b[39m     lr: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.001\u001b[39m,\n\u001b[32m     15\u001b[39m     weight_decay: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.0\u001b[39m,\n\u001b[32m     16\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     17\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Initialize the optimizer.\u001b[39;00m\n\u001b[32m     18\u001b[39m \n\u001b[32m     19\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m \u001b[33;03m        weight_decay: L2 regularization factor\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28mself\u001b[39m.param_groups = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_param_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28mself\u001b[39m.state: Dict[Tuple[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, np.ndarray]] = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\nn\\optim.py:47\u001b[39m, in \u001b[36mOptimizer._make_param_groups\u001b[39m\u001b[34m(self, raw_params, lr, weight_decay)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_param_groups\u001b[39m(\n\u001b[32m     40\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     41\u001b[39m     raw_params: Dict[\u001b[38;5;28mstr\u001b[39m, np.ndarray],\n\u001b[32m     42\u001b[39m     lr: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[32m     43\u001b[39m     weight_decay: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[32m     44\u001b[39m ) -> List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m     45\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convert a dict of parameters into a standard param group.\"\"\"\u001b[39;00m\n\u001b[32m     46\u001b[39m     flat_params: List[Tuple[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mstr\u001b[39m, np.ndarray]] = [\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m         (\u001b[38;5;28;01mNone\u001b[39;00m, name, param) \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m \u001b[43mraw_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m()\n\u001b[32m     48\u001b[39m     ]\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [{\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: flat_params, \u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m: lr, \u001b[33m\"\u001b[39m\u001b[33mweight_decay\u001b[39m\u001b[33m\"\u001b[39m: weight_decay}]\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "raw_params = {}\n",
    "for i, layer in enumerate(model.layers):\n",
    "    for name, param in layer.params().items():\n",
    "        raw_params[f\"layer{i}_{name}\"] = param\n",
    "\n",
    "optimizer = Adam(raw_params, lr=0.001)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9991524b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 14:26:42,310 - DEBUG - Training started.\n",
      "2025-11-02 14:26:42,310 - root - DEBUG - Training started.\n",
      "2025-11-02 14:26:42,313 - DEBUG - Starting epoch 1/10.\n",
      "2025-11-02 14:26:42,313 - root - DEBUG - Starting epoch 1/10.\n",
      "2025-11-02 14:26:43,161 - DEBUG - Processing training batch with 128 samples.\n",
      "2025-11-02 14:26:43,161 - root - DEBUG - Processing training batch with 128 samples.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train the model using the train function\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_losses, val_losses, train_accs, val_accs = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\train.py:43\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_loader, val_loader, loss_fn, optimiser, num_epochs, batch_size, checkpoint_dir, log_dir)\u001b[39m\n\u001b[32m     41\u001b[39m optimiser.zero_grad()\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Loss and gradient\u001b[39;00m\n\u001b[32m     45\u001b[39m loss, grad_output = loss_fn(output, b_labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\nn\\layers\\sequential.py:31\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, x, training)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33;03mPerform the forward pass of the layer.\u001b[39;00m\n\u001b[32m     21\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m \u001b[33;03m    np.ndarray: The output of the layer.\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     x = \u001b[43mlayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\nn\\layers\\maxpool2d.py:33\u001b[39m, in \u001b[36mMaxPool2D.forward\u001b[39m\u001b[34m(self, x, training)\u001b[39m\n\u001b[32m     30\u001b[39m out_W = \u001b[32m1\u001b[39m + (W + \u001b[32m2\u001b[39m * padding - pool_W) // stride\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Convert input to columns\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m cols = \u001b[43mimage_to_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_H\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m cols_reshaped = cols.reshape(C, pool_H * pool_W, N * out_H * out_W)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Max pooling\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\nn\\utils.py:52\u001b[39m, in \u001b[36mimage_to_column\u001b[39m\u001b[34m(x, kernel_size, stride, padding)\u001b[39m\n\u001b[32m     50\u001b[39m             \u001b[38;5;66;03m# Extract the current patch and flatten it\u001b[39;00m\n\u001b[32m     51\u001b[39m             patch = x_padded[n, :, h_start:h_end, w_start:w_end]\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m             cols[:, n * out_H * out_W + i * out_W + j] = \u001b[43mpatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cols\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model using the train function\n",
    "train_losses, val_losses, train_accs, val_accs = train(\n",
    "    model, train_loader, val_loader, loss_fn, optimizer, num_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e59078-fd11-4c3c-9310-9c6375ee1569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 14:26:57,736 - DEBUG - Starting fold 1/5.\n",
      "2025-11-02 14:26:57,736 - root - DEBUG - Starting fold 1/5.\n",
      "2025-11-02 14:26:57,736 - root - DEBUG - Starting fold 1/5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 14:26:58,094 - DEBUG - Training started.\n",
      "2025-11-02 14:26:58,094 - root - DEBUG - Training started.\n",
      "2025-11-02 14:26:58,094 - root - DEBUG - Training started.\n",
      "2025-11-02 14:26:58,094 - root - DEBUG - Training started.\n",
      "2025-11-02 14:26:58,101 - DEBUG - Starting epoch 1/10.\n",
      "2025-11-02 14:26:58,101 - root - DEBUG - Starting epoch 1/10.\n",
      "2025-11-02 14:26:58,101 - root - DEBUG - Starting epoch 1/10.\n",
      "2025-11-02 14:26:58,101 - root - DEBUG - Starting epoch 1/10.\n",
      "2025-11-02 14:26:58,221 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:26:58,221 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:26:58,221 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:26:58,221 - root - DEBUG - Processing training batch with 32 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41472 10368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 14:27:00,608 - DEBUG - Training batch loss: 7.702752763073777\n",
      "2025-11-02 14:27:00,608 - root - DEBUG - Training batch loss: 7.702752763073777\n",
      "2025-11-02 14:27:00,608 - root - DEBUG - Training batch loss: 7.702752763073777\n",
      "2025-11-02 14:27:00,608 - root - DEBUG - Training batch loss: 7.702752763073777\n",
      "2025-11-02 14:27:04,329 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-11-02 14:27:04,329 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-11-02 14:27:04,329 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-11-02 14:27:04,329 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-11-02 14:27:04,335 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:27:04,335 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:27:04,335 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:27:04,335 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:27:06,597 - DEBUG - Training batch loss: 16.070182755513525\n",
      "2025-11-02 14:27:06,597 - root - DEBUG - Training batch loss: 16.070182755513525\n",
      "2025-11-02 14:27:06,597 - root - DEBUG - Training batch loss: 16.070182755513525\n",
      "2025-11-02 14:27:06,597 - root - DEBUG - Training batch loss: 16.070182755513525\n",
      "2025-11-02 14:27:10,589 - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-11-02 14:27:10,589 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-11-02 14:27:10,589 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-11-02 14:27:10,589 - root - DEBUG - Training batch accuracy: 0.0625\n",
      "2025-11-02 14:27:10,598 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:27:10,598 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:27:10,598 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:27:10,598 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:27:12,401 - DEBUG - Training batch loss: 18.1520341917851\n",
      "2025-11-02 14:27:12,401 - root - DEBUG - Training batch loss: 18.1520341917851\n",
      "2025-11-02 14:27:12,401 - root - DEBUG - Training batch loss: 18.1520341917851\n",
      "2025-11-02 14:27:12,401 - root - DEBUG - Training batch loss: 18.1520341917851\n",
      "2025-11-02 14:27:16,911 - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-11-02 14:27:16,911 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-11-02 14:27:16,911 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-11-02 14:27:16,911 - root - DEBUG - Training batch accuracy: 0.03125\n",
      "2025-11-02 14:27:16,920 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:27:16,920 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:27:16,920 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:27:16,920 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:27:19,247 - DEBUG - Training batch loss: 14.73845298028628\n",
      "2025-11-02 14:27:19,247 - root - DEBUG - Training batch loss: 14.73845298028628\n",
      "2025-11-02 14:27:19,247 - root - DEBUG - Training batch loss: 14.73845298028628\n",
      "2025-11-02 14:27:19,247 - root - DEBUG - Training batch loss: 14.73845298028628\n",
      "2025-11-02 14:27:22,840 - DEBUG - Training batch accuracy: 0.15625\n",
      "2025-11-02 14:27:22,840 - root - DEBUG - Training batch accuracy: 0.15625\n",
      "2025-11-02 14:27:22,840 - root - DEBUG - Training batch accuracy: 0.15625\n",
      "2025-11-02 14:27:22,840 - root - DEBUG - Training batch accuracy: 0.15625\n",
      "2025-11-02 14:27:22,852 - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:27:22,852 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:27:22,852 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:27:22,852 - root - DEBUG - Processing training batch with 32 samples.\n",
      "2025-11-02 14:27:24,883 - DEBUG - Training batch loss: 20.59354535792522\n",
      "2025-11-02 14:27:24,883 - root - DEBUG - Training batch loss: 20.59354535792522\n",
      "2025-11-02 14:27:24,883 - root - DEBUG - Training batch loss: 20.59354535792522\n",
      "2025-11-02 14:27:24,883 - root - DEBUG - Training batch loss: 20.59354535792522\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_root\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./checkpoints/crossval/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./logs/crossval/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\crossval.py:88\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(model, loss_fn, optimizer, num_epochs, batch_size, k, seed, log_dir, checkpoint_root)\u001b[39m\n\u001b[32m     85\u001b[39m train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     86\u001b[39m val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m train_losses, val_losses, train_accs, val_accs = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold_ckpt_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold_log_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m logger.log_debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinished training fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    101\u001b[39m final_train_loss = train_losses[-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m train_losses \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\train.py:48\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_loader, val_loader, loss_fn, optimiser, num_epochs, batch_size, checkpoint_dir, log_dir)\u001b[39m\n\u001b[32m     46\u001b[39m logger.log_debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining batch loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m optimiser.step()\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Accumulate metrics\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\nn\\layers\\sequential.py:46\u001b[39m, in \u001b[36mSequential.backward\u001b[39m\u001b[34m(self, dout)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[33;03mPerform the backward pass of the layer.\u001b[39;00m\n\u001b[32m     38\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     43\u001b[39m \u001b[33;03m    np.ndarray: The downstream gradient.\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m.layers):\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     dout = \u001b[43mlayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dout\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\nn\\layers\\conv2d.py:111\u001b[39m, in \u001b[36mConv2D.backward\u001b[39m\u001b[34m(self, dout)\u001b[39m\n\u001b[32m    109\u001b[39m weights_matrix = \u001b[38;5;28mself\u001b[39m.weights.reshape(F, -\u001b[32m1\u001b[39m)\n\u001b[32m    110\u001b[39m dx_cols = weights_matrix.T @ dout_reshaped\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m dx = \u001b[43mcolumn_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdx_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dx\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\nn\\utils.py:103\u001b[39m, in \u001b[36mcolumn_to_image\u001b[39m\u001b[34m(dx_cols, x_shape, kernel_size, stride, padding)\u001b[39m\n\u001b[32m    101\u001b[39m             \u001b[38;5;66;03m# Extract the current patch and reshape it\u001b[39;00m\n\u001b[32m    102\u001b[39m             patch = dx_cols[:, n * out_H * out_W + i * out_W + j]\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m             dx[n, :, h_start:h_end, w_start:w_end] += \u001b[43mpatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m                \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# Remove the padding, if necessary.\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m padding > \u001b[32m0\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results = cross_validate(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    checkpoint_root=\"./checkpoints/crossval/\",\n",
    "    log_dir=\"./logs/crossval/\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
