{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ab95637",
   "metadata": {},
   "source": [
    "# Nature CNN Recreation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca6f2956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b864d1",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9275c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.utils import one_hot_encode, export_encoded_labels\n",
    "from dataio.gtsrb_dataset import GTSRBDataset\n",
    "import numpy as np\n",
    "\n",
    "chosen_classes = {1, 2, 10, 13, 38}\n",
    "\n",
    "dataset = GTSRBDataset()\n",
    "labels = dataset.labels_data\n",
    "\n",
    "filtered_indices = [i for i, (_, label) in enumerate(labels) if label in chosen_classes]\n",
    "\n",
    "class_indices = {cls: [] for cls in chosen_classes}\n",
    "for idx in filtered_indices:\n",
    "    _, label = labels[idx]\n",
    "    class_indices[label].append(idx)\n",
    "\n",
    "clipped_indices = []\n",
    "for cls in chosen_classes:\n",
    "    indices = class_indices[cls]\n",
    "    if len(indices) > 2500:\n",
    "        indices = np.random.choice(indices, size=2500, replace=False)\n",
    "    clipped_indices.extend(indices)\n",
    "\n",
    "clipped_indices = np.array(clipped_indices)\n",
    "np.random.shuffle(clipped_indices)\n",
    "\n",
    "label_to_index = {label: idx for idx, label in enumerate(chosen_classes)}\n",
    "mapped_labels = np.array([label_to_index[labels[i][1]] for i in clipped_indices])\n",
    "\n",
    "num_classes = len(chosen_classes)\n",
    "one_hot_labels = one_hot_encode(mapped_labels, num_classes)\n",
    "\n",
    "filtered_csv_path = export_encoded_labels(\n",
    "    dataset=GTSRBDataset(),\n",
    "    chosen_classes=chosen_classes,\n",
    "    clipped_indices=clipped_indices,\n",
    "    output_name=\"filtered_labels_encoded.csv\"\n",
    ")\n",
    "\n",
    "filtered_dataset = GTSRBDataset(labels=\"filtered_labels_encoded.csv\")\n",
    "num_samples = len(filtered_dataset)\n",
    "\n",
    "train_end = int(0.85 * num_samples)\n",
    "train_split = list(range(train_end))\n",
    "test_split = list(range(train_end, num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5cda826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataio.transforms import ToCompose, ToGrayscale, ToResize, ToTensor, ToNormalize\n",
    "from dataio.dataloader import DataLoader\n",
    "\n",
    "# Set up the data transformations to match the original nature CNN.\n",
    "train_transforms = ToCompose([\n",
    "    ToGrayscale(),\n",
    "    ToResize(size=28),\n",
    "    ToTensor(),\n",
    "    ToNormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "val_transforms = ToCompose([\n",
    "    ToGrayscale(),\n",
    "    ToResize(size=28),\n",
    "    ToTensor(),\n",
    "    ToNormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85822b5",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3441feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.layers.conv2d import Conv2D\n",
    "from nn.layers.flatten import Flatten\n",
    "from nn.layers.linear import Linear\n",
    "from nn.layers.maxpool2d import MaxPool2D\n",
    "from nn.layers.sequential import Sequential\n",
    "from nn.layers.activation import Activation\n",
    "from nn.activations import relu\n",
    "from nn.__init__ import he_init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd852c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.loss import mse\n",
    "\n",
    "# Define the loss function.\n",
    "# The original CNN used MSE.\n",
    "loss_fn = mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47699ed1",
   "metadata": {},
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "398b091a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hyperparameters: lr=0.001, wd=0.0001\n",
      "10000 2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 13:06:46,113 - root - INFO - Epoch 1/10, Train Loss: 1.7933,Train Accuracy: 0.1991\n",
      "2025-11-03 13:06:46,113 - root - INFO - Epoch 1/10, Train Loss: 1.7933,Train Accuracy: 0.1991\n",
      "2025-11-03 13:07:05,064 - root - INFO - Epoch 1/10,Val Loss: 1.7757, Val Accuracy: 0.1945\n",
      "2025-11-03 13:07:05,064 - root - INFO - Epoch 1/10,Val Loss: 1.7757, Val Accuracy: 0.1945\n",
      "2025-11-03 13:08:32,275 - root - INFO - Epoch 2/10, Train Loss: 1.8111,Train Accuracy: 0.1999\n",
      "2025-11-03 13:08:32,275 - root - INFO - Epoch 2/10, Train Loss: 1.8111,Train Accuracy: 0.1999\n",
      "                                                               \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTesting hyperparameters: lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, wd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[33m'\u001b[39m\u001b[33mwd\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m model = make_model()\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiltered_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmake_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwd\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_transforms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_transforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_transforms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_transforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\n\u001b[32m     47\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\crossval.py:136\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(model_fn, dataset, loss_fn, optimizer_fn, train_transforms, val_transforms, num_epochs, batch_size, k, seed, log_dir, checkpoint_root)\u001b[39m\n\u001b[32m    133\u001b[39m optimizer = optimizer_fn(param_dict)\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# Train.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m train_losses, val_losses, train_accs, val_accs = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold_ckpt_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold_log_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m logger.log_debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinished training fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    148\u001b[39m \u001b[38;5;66;03m# Metrics.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\train.py:106\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_loader, val_loader, loss_fn, optimiser, num_epochs, checkpoint_dir, log_dir)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m b_data, b_labels \u001b[38;5;129;01min\u001b[39;00m val_loop:\n\u001b[32m    105\u001b[39m     n_val_samples += b_data.shape[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     output = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     loss, _ = loss_fn(output, b_labels)\n\u001b[32m    108\u001b[39m     epoch_val_loss += loss * b_data.shape[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\nn\\layers\\sequential.py:35\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, x, training)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Perform the forward pass of the layer.\u001b[39;00m\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m \u001b[33;03m    np.ndarray: The output of the layer.\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     x = \u001b[43mlayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\nn\\layers\\maxpool2d.py:59\u001b[39m, in \u001b[36mMaxPool2D.forward\u001b[39m\u001b[34m(self, x, training)\u001b[39m\n\u001b[32m     56\u001b[39m out_W = \u001b[32m1\u001b[39m + (W + \u001b[32m2\u001b[39m * padding - pool_W) // stride\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Convert input to columns.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m cols = \u001b[43mimage_to_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_H\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m cols_reshaped = cols.reshape(C, pool_H * pool_W, N * out_H * out_W)\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Max pooling.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Gebruiker\\Documents\\YEAR 3\\Neural Networks\\traffic-sign-classification\\nn\\utils.py:57\u001b[39m, in \u001b[36mimage_to_column\u001b[39m\u001b[34m(x, kernel_size, stride, padding)\u001b[39m\n\u001b[32m     55\u001b[39m             \u001b[38;5;66;03m# Extract the current patch and flatten it.\u001b[39;00m\n\u001b[32m     56\u001b[39m             patch = x_padded[n, :, h_start:h_end, w_start:w_end]\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m             cols[:, n * out_H * out_W + i * out_W + j] = \u001b[43mpatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cols\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from crossval import cross_validate\n",
    "from nn.optim import Momentum\n",
    "\n",
    "# Perform cross-validation for hyperparameter tuning.\n",
    "num_epochs = 10\n",
    "hyperparameters = [\n",
    "    {\"lr\": 0.001, \"wd\": 1e-4},\n",
    "    {\"lr\": 0.005, \"wd\": 5e-4},\n",
    "    {\"lr\": 0.01, \"wd\": 1e-3},\n",
    "]\n",
    "all_results = []\n",
    "\n",
    "def make_optimizer(model_params, lr: float, wd: float):\n",
    "    return Momentum(model_params, lr=lr, weight_decay=wd)\n",
    "\n",
    "\n",
    "def make_model():\n",
    "    return Sequential([\n",
    "    Conv2D(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0, weight_init=he_init),\n",
    "    Activation(relu),\n",
    "    MaxPool2D(pool_size=2, stride=2),\n",
    "    Conv2D(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, weight_init=he_init),\n",
    "    Activation(relu),\n",
    "    MaxPool2D(pool_size=2, stride=2),\n",
    "    Flatten(),\n",
    "    Linear(in_features=256, out_features=120, weight_init=he_init),\n",
    "    Activation(relu),\n",
    "    Linear(in_features=120, out_features=84, weight_init=he_init),\n",
    "    Activation(relu),\n",
    "    Linear(in_features=84, out_features=5, weight_init=he_init)\n",
    "])\n",
    "\n",
    "\n",
    "for params in hyperparameters:\n",
    "    print(f\"Testing hyperparameters: lr={params['lr']}, wd={params['wd']}\")\n",
    "    model = make_model()\n",
    "\n",
    "    results = cross_validate(\n",
    "        model_fn=make_model,\n",
    "        dataset=filtered_dataset,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer_fn=lambda p: make_optimizer(p, params['lr'], params['wd']),\n",
    "        train_transforms=train_transforms,\n",
    "        val_transforms=val_transforms,\n",
    "        num_epochs=num_epochs,\n",
    "        batch_size=64\n",
    "    )\n",
    "\n",
    "    all_results.append({\n",
    "        \"lr\": params['lr'],\n",
    "        \"wd\": params['wd'],\n",
    "        \"fold_results\": results\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99916b4c",
   "metadata": {},
   "source": [
    "## Result Evaluation and Greedy Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.4395, Test Accuracy: 0.2023\n"
     ]
    }
   ],
   "source": [
    "for res in all_results:\n",
    "    val_accs = [fold[\"val_acc\"] for fold in res[\"fold_results\"]]\n",
    "    val_losses = [fold[\"val_loss\"] for fold in res[\"fold_results\"]]\n",
    "    \n",
    "    res[\"mean_val_acc\"] = np.mean(val_accs)\n",
    "    res[\"mean_val_loss\"] = np.mean(val_losses)\n",
    "    \n",
    "    print(f\"lr={res['lr']}, wd={res['wd']}: \"\n",
    "          f\"Mean Val Acc={res['mean_val_acc']:.4f}, \"\n",
    "          f\"Mean Val Loss={res['mean_val_loss']:.4f}\")\n",
    "    \n",
    "best = max(all_results, key=lambda r: r[\"mean_val_acc\"])\n",
    "print(\"Best hyperparameters:\")\n",
    "print(f\"lr={best['lr']}, wd={best['wd']}, Mean Val Acc={best['mean_val_acc']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
